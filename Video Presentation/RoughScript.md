# Title Slide
Hello. Today I will be presenting the Ragin Cajun RoboBoat Team's design for the 2020 RoboBoat competition.
Our team represents the University of Louisiana at Lafayette. This is the Ragin' Cajuns' second year competing
in RoboBoat.

# Members Slide
## Benjamin Armentor
My name is Benjamin Armentor, I am the Ragin Cajuns Team Captain and a Master's Student in Mechanical ENGR. I oversee all of our subteams and am responsible for the majority of software development on-board.

## Joseph Stevens
Our team's vice captain is Joseph Stevens, a junior in MCHE. Joseph is responsible for hardware development and project CAD management.

## Dallas Mitchell
There are 6 other students working on this project, all of which are either graduate or undergraduate students in MCHE. On the software side, we have Dallas Mitchell, who assists with developing the computer vision systems.

## Gerald Eaglin
Gerald Eaglin is in charge of the mapping, navigation, and localization systems on-board.
He is also responsible for the design of the state machine behaviors.

## Nathan Madsen and Andrew Durand
Lastly, Nathan Madsen and Andrew Durand have assisted me with the development of the controller.

## Bradley Este and Thomas Poche
On the hardware team, we have Bradley Este and Thomas Poche who work with Joseph, and have focused primarily on thermal energy management.

## Dr. Vaughan
Our team is coached by Dr. Joshua Vaughan. Dr. Vaughan leads the CRAWLab at our university, a research group consisting primarily of MCHE students focusing on developing robotics and control systems.

Now that we've met the team, let's see what everyone's been working on.

# Design Overview
## Labeled RoboBoat Render
This is the 2020 Ragin Cajun RoboBoat. Like I said previously, this is the second year that our team has competed in RoboBoat, so much of this design has built off of the 2019 team's design.

## E-Stop Video
The Ragin Cajun RoboBoat has hardware E-stops at both Port and Starboard. If these, or our E-Stop Remote on-shore, are pressed, all power to the propulsion system is killed, and the vessel is put into E-Stop mode. This is denoted by the Status Lights on an antenna. Red represents E-Stop Mode and Green represents Autonomous Mode. The shore remote communicates to the boat through LoRA.

Our shore computers talk to the boat through Wi-Fi communications.

A GPS receiver is mounted on the same antenna as the E-Stop/Autonomous Status Lights. This feedback is used in the RoboBoat's navigation and localization systems. This is the primary form of position feedback if there are no objects to track in the visual feedback.

Inside of the electrical enclosure, there is an IMU for additional pose estimates and acceleration feedback, a Raspberry Pi for Motor Control, two Jetson TX2s, one each for the control and vision pipelines, and miscellaneous support electronics. All of these sensors and computers communicate using the Robot Operating System, or ROS.

## CAD RoboBoat alternative view
In this year's design, we've also replaced the enclosure. The previous enclosure was made out of black polypropylene, but this one is a fiberglass case with a light gray finish. This increases the enclosure's albedo, which, in turn, reduces the amount of heat absorbed.

We have also elevated the enclosure off the hull slightly to allow space for a set of finned plates, which serve as a heat sink. When the RoboBoat is moving forward, the relative velocity between the plates and the air will act as forced convection, increasing the amount of heat rejected by the system.

The new enclosure also has increased the convective area by approximately 160%. When considering all of these factors, the enclosure should increase the heat rejected by nearly 51%. While this is nice for our electronics, we have decreased our thrust-to-weight ratio by doing so, because this enclosure does add approximately 10 lbs to the design. The team decided this was an acceptable tradeoff for an increase in performance by using an optimal control method, enabled by our increased computational power.

## Control Strategy
### General Info
The optimal control method that was chosen for the control system is Model Predictive Control. Other researchers have already applied this method to maritime tracking control. Based on their results, we believed it would be a good fit for our system as well.

This control method solves an optimization problem over the next *n* time steps, where *n* is finite. The optimal control sequence, *u-hat* is generated by predicting where the system will be based on the equations of motion representing the system and the minimization of a performance index. This performance index is commonly called a cost function.

As the name suggests, the controller requires a model, which is used to make those future state predictions. This control method is also not limited to linear systems, whereas some optimal control methods like Linear Quadratic Regulation, are limited to these types of systems.

The first input of *u-hat* is supplied to the actuators, new initital conditions are measured from the sensors on-board, and the process is then repeated.

### Cost Function
The cost function used to quantify system performance is typically chosen to be convex, but it is not required to be. This quadratic cost representation is given by this finite summation over *n* steps, where *x* is a vector of state error, *u* is the control input vector, and *Q* and *R* are weight matrices, typically chosen to be diagonal.

During the solution process, the control input vector *u* is updated using an optimization method to see how the state vector *x* is affected.

This quadratic representation has a minimum at zero, which occurs when there is no error from what the controller is trying to track _and_ we're not applying any input to the system.

### Single DOF MPC T0
Here is an example of a MPC controller tracking a constant setpoint, shown in red, on a single DOF system. The past system states are shown in blue to the left of the vertical line. The past input to the system is shown in purple.

At the current time step, which occurs at the vertical line, we will predict the next *n* control inputs to the system that minimize our error from the red line. The predicted states are shown in green.

The optimal input sequence, shown in orange, is what results in the predicted system states. Once the cost function has been minimized, the first value of the orange line is applied to the system to advance it toward the red line.

### Single DOF MPC T1
Depending on how well the model provided to the controller to predict future states matches with the real system, there may be some disparity between the predicted and actual values, so we re-sample. Now, our vertical line and prediction horizon has shifted, and we solve for the optimal control sequence again.

### Comparison to Old Control Strategy
The 2019 control strategy simply mapped the difference between the desired and current velocities by minimizing a Euclidean norm and mapping the percent change to each thruster. This new control strategy can see how changing the thrust input on one motor will affect the states independently. This should lead to more accurate tracking performance, provided our system model is representative of the real RoboBoat.

The optimization procedure to minimize the cost function can be very computationally expensive, which is one drawback of this control method. Also, the inputs must be supplied to the system at or above the sampling rate of the controller, which bounds our maximum available solution time.

To overcome this, our controller utilizes a real-time algorithm implemented by the ACADO toolkit. This will limit the computation time to generate the optimal control sequence and supply the current best guess to the actuators, even if the KKT conditions for optimization have not been met.


## Actuator Configuration
Our actuators are mounted in an "X" configuration at 45-degree angles. This allows the RoboBoat to achieve holonomic motion.

This diagram shows how we can apply thrust to move in each degree of freedom independently. Some combination of these three basic examples can generate motion in any prescribed direction.

### Planar LiDAR and Stereo Camera Vision
Though we had this same thruster configuration before, we did not have a vision system that could use it without risk.

Here we have a top-down view of the RoboBoat. The 2019 design had a planar LiDAR and stereo camera at the bow. This produced a field of view that looked like this. As you can see, the stern of the vessel has no visual feedback, which means we ran the risk of encountering obstacles if they were not tracked on the map properly.

The 2020 design helps to patch this gap by mirroring the 2019's vision system on the stern. Now, we have a field of view with only two blind spots, immediately adjacent to the hull.

The readings of these cameras are fed into an image classifier trained via manually labeled images of buoys and docks from the 2016 Maritime RobotX competition. The image classifier uses "You Only Look Once -- Version 3" or YOLOv3.

# Competition Strategy
We will now discuss our team's strategy for the competition. We attempt all but the Object Delivery task, with Acoustic Docking immediately following the Navigation Channel. This is because information at the Docking Task may inform future decisions.

## State Machine
The RoboBoat has a high-level state machine that governs its behavior. It communicates with sensors via ROS and puts the system into different states. The transitions between states are finite and manually defined by the team. This allows for a group of tasks to be strung together logically.

The behaviors used on the majority of tasks include Determining where a waypoint should be, Choosing one or more waypoints as goal locations, moving to the chosen waypoints, and searching for buoys. This is done by analyzing the visual feedback.

Some tasks, like the acoustic docking and obstacle field, have more specific states pertaining to hydrophone signal processing, docking, and measuring gaps in the obstacle field to find the widest opening.

A preliminary set of transitions between tasks and behaviors, like this one, has been outlined for each task. We planned to adjust our transitions between states at the competition during practice runs, should our RoboBoat respond poorly.

## Path Planning, Localization, and Navigation
Upon a task's completion, the RoboBoat maneuvers to the next GPS coordinate for the following task. Together with our path planner, localization, and navigation systems, our RoboBoat should be able to make logical transitions between tasks by inspecting what is in the field of view and tracking a trajectory through the chosen waypoints.

# Experimental Testing
## Pool Testing
Due to the ongoing pandemic, much of our proposed design has not been completed due to restricted access to university resources, practicing social distancing, and adjusting to virtual classroom environments.

Before these restrictions were in place, the Ragin' Cajun RoboBoat team was able to perform some system identification tests in a university pool. This enabled us to build up a model of the system for our controller.

All of these tests were performed before the new enclosure arrived, so with different inertial properties, our hydrodynamics will also change.

We have estimated what the RoboBoat's new draft will be from the added enclosure weight. This, along with the data recorded at the pool testing sessions and other researchers' catamaran system identification publications, has resulted in these values for our hydrodynamic parameters.

The parameters follow the SNAME convention, meaning the force or moment is induced by motion in the subscripted direction. We will perform more system identification trials once the new enclosure is configured and university resources are made available.

## Gazebo Simulation
After the competition was cancelled and the team had limited access to the RoboBoat, much of the development efforts were devoted to creating a Gazebo simulation.

The simulation is based on Clearpath Robotics' Heron Simulator. We have spawned our RoboBoat in the Sand Island world from the 2019 Virtual RobotX competition. So far, we've been able to test our localization, computer vision feedback, and image classification.

By next year's competition, this simulator will be fully-functional and easy to interface with to test individual nodes or sensors. It is our hope that this helps to further our maritime autonomy research at our university and aid future Ragin' Cajun RoboBoaters.

## Conclusion
Thank you for listening to our presentation on the 2020 RoboBoat Design from the University of Louisiana at Lafayette. We would like to thank our sponsors who generously donated the new enclosure to our team.

We could not have developed our design without the prior work of others. Thank you to the 2019 team for constructing the base platform we've improved upon. Here is a list of references that helped us to build our system model and simulation.

Until next year, this has been the University of Louisiana at Lafayette, signing off.